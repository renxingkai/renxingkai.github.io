<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="推荐系统排序模型-从LR到XXXX"><meta name="keywords" content="排序 - 推荐系统"><meta name="author" content="CinKate"><meta name="copyright" content="CinKate"><title>推荐系统排序模型-从LR到XXXX | CinKate's Blogs</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?b77222dd6b9929f160b8a04fc8705337";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '3.9.0'
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-LR-逻辑回归"><span class="toc-number">1.</span> <span class="toc-text">1. LR-逻辑回归</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-POLY2-特征交叉的开始"><span class="toc-number">2.</span> <span class="toc-text">2.POLY2-特征交叉的开始</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-FM-隐向量特征交叉"><span class="toc-number">3.</span> <span class="toc-text">3.FM-隐向量特征交叉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-FFM"><span class="toc-number">4.</span> <span class="toc-text">4.FFM</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-DeepFM"><span class="toc-number">5.</span> <span class="toc-text">5.DeepFM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Sparse-Feature"><span class="toc-number">5.0.1.</span> <span class="toc-text">5.1 Sparse Feature</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Dense-Embeddings"><span class="toc-number">5.0.2.</span> <span class="toc-text">5.2 Dense Embeddings</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-FM-Layer"><span class="toc-number">5.0.3.</span> <span class="toc-text">5.3 FM Layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-Hidden-Layer"><span class="toc-number">5.0.4.</span> <span class="toc-text">5.4 Hidden Layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-Output-Units"><span class="toc-number">5.0.5.</span> <span class="toc-text">5.5 Output Units</span></a></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#6-DCN"><span class="toc-number">6.</span> <span class="toc-text">6.DCN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-Embedding-Layer"><span class="toc-number">6.0.1.</span> <span class="toc-text">6.1 Embedding Layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-Cross-Network"><span class="toc-number">6.0.2.</span> <span class="toc-text">6.2 Cross Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-Deep-Network"><span class="toc-number">6.0.3.</span> <span class="toc-text">6.3 Deep Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-4-Combination-Output-Layer"><span class="toc-number">6.0.4.</span> <span class="toc-text">6.4 Combination Output Layer</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-DCN-v2"><span class="toc-number">7.</span> <span class="toc-text">7.DCN_v2</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#参考链接"><span class="toc-number">7.1.</span> <span class="toc-text">参考链接</span></a></li></ol></li></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="http://imgsrc.baidu.com/forum/w%3D580/sign=f8de0e9b3e87e9504217f3642039531b/1c3bd133c895d143e395e57b77f082025baf0726.jpg"></div><div class="author-info__name text-center">CinKate</div><div class="author-info__description text-center">长笛一声人倚楼~</div><div class="follow-button"><a href="https://github.com/renxingkai">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">49</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">32</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">17</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(http://p17.qhimg.com/d/_open360/fengjing0403/21.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">CinKate's Blogs</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">推荐系统排序模型-从LR到XXXX</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-07-27</time><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">4.4k</span><span class="post-meta__separator">|</span><span>Reading time: 19 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>平时会用到不少的排序模型，但是一直没有系统化总结，今天还是认真总结下，如有错误，求大佬们不吝指出。</p>
<h1 id="1-LR-逻辑回归"><a href="#1-LR-逻辑回归" class="headerlink" title="1. LR-逻辑回归"></a>1. LR-逻辑回归</h1><p>逻辑回归通常对输入特征如用户年龄、性别、item属性、描述等进行变换，然后输入到模型中，通常训练目标为是否点击。在推理阶段，将同样的特征输入到模型中，模型预测出点击概率，最终经过排序得到推荐item的列表。</p>
<p>逻辑回归核心为sigmoid函数，wx输入到sigmoid函数中，通常使用梯度下降算法来更新参数w。</p>
<p>逻辑回归的优点：</p>
<ul>
<li>强数学含义支撑。LR属于广义线性模型的一种。</li>
<li>可解释性强。从公式层面来看，LR数学形式就是不同特征之间的加权之和，最终过一个sigmoid函数，将输出值限制在0到1之间。根据不同特征的权重，可以明显观察到哪些特征重要。</li>
<li>工程实现容易。</li>
</ul>
<p>逻辑回归的缺点：</p>
<ul>
<li>表示能力不足。</li>
<li>无法进行特征交叉，学习高阶特征。</li>
</ul>
<h1 id="2-POLY2-特征交叉的开始"><a href="#2-POLY2-特征交叉的开始" class="headerlink" title="2.POLY2-特征交叉的开始"></a>2.POLY2-特征交叉的开始</h1><p>LR存在无法自动进行特征交叉的问题，最容易想到的是人工构造交叉组合特征。公式如下：</p>
<p><code>$ POLY2(w,x)=\sum_{j_1=i}^{n-1} \sum_{j_2=j_1+1}^{n} w_{h(j_1,j_2)}x_{j_1}x_{j_2}$</code></p>
<p>可以看到，该方法对所有特征均进行交叉，并对特征组合赋予权重<br><code>$ w_{h(j_1,j_2)} $</code>，一定程度解决了特征交叉问题，但是本质上还是对于不同特征加权求和的线性模型。</p>
<p>POLY2缺点：</p>
<ul>
<li>交叉特征容易出现极度稀疏问题。使用one-hot编码类别特征之后，容易出现稀疏特征问题。</li>
<li>权重参数由n上升到n2，增加训练复杂度。</li>
</ul>
<h1 id="3-FM-隐向量特征交叉"><a href="#3-FM-隐向量特征交叉" class="headerlink" title="3.FM-隐向量特征交叉"></a>3.FM-隐向量特征交叉</h1><p>FM的主要优点是解决稀疏数据下的特征组合问题。<br>原始的FM公式为：</p>
<p><code>$ FM=w_0+\sum_{i=1}^n w_ix_i+\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} w_{ij}x_ix_j$</code></p>
<p>前两项其实就是一阶加权特征，计算复杂度为O(n)，第三项中的权重<code>$w_{ij}$</code>，这儿使用到了矩阵分解，分解为 <code>$ W=V^TV $</code>, vi、vj分别为xi、xj的隐向量<br><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220712231715.png" alt></p>
<p>于是，原始公式变为了：</p>
<p><code>$ FM=w_0+\sum_{i=1}^n w_ix_i+\sum_{i=1}^{n} \sum_{j=i+1}^{n} &lt;v_i,v_j&gt;x_ix_j$</code></p>
<p>我们假设隐向量的长度为k ，那么交叉项的参数量变为 kn 个。此时时间复杂度仍为O(kn^2)，通过以下方式可以简化为O(kn)，如下图：<br><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220712232204.png" alt></p>
<p>附上核心代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class FactorizationMachine(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">        Factorization Machine</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, feature_fields, embed_dim):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">            feature_fileds : array_like</span><br><span class="line">                             类别特征的field的数目</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        super(FactorizationMachine, self).__init__()</span><br><span class="line"></span><br><span class="line">        # 输入的是label coder 用输出为1的embedding来形成linear part</span><br><span class="line">        self.linear = torch.nn.Embedding(sum(feature_fields) + 1, 1)</span><br><span class="line">        self.bias = torch.nn.Parameter(torch.zeros((1,)))</span><br><span class="line"></span><br><span class="line">        self.embedding = torch.nn.Embedding(sum(feature_fields) + 1, embed_dim)</span><br><span class="line">        self.offset = np.array((0, *np.cumsum(feature_fields)[:-1]), dtype=np.long)</span><br><span class="line">        nn.init.xavier_uniform_(self.embedding.weight.data)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        tmp = x + x.new_tensor(self.offset).unsqueeze(0)  # bs,fields_num [bs,22]</span><br><span class="line"></span><br><span class="line">        # 线性层</span><br><span class="line">        # bs,fields_num,1 -&gt; bs,1 [bs,22,1]-&gt;[bs,1]</span><br><span class="line">        linear_part = torch.sum(self.linear(tmp), dim=1) + self.bias</span><br><span class="line">        # print(&quot;linear_part shape&quot;, linear_part.shape)</span><br><span class="line"></span><br><span class="line">        # 内积项</span><br><span class="line">        ## embedding</span><br><span class="line">        # [bs,1] -&gt; bs,1,embedding_dim [bs,1,8]</span><br><span class="line">        tmp = self.embedding(tmp)</span><br><span class="line">        ##  XY</span><br><span class="line">        # bs,1,embedding_dim -&gt; bs,embedding_dim;; [bs,1,8]-&gt;bs,8</span><br><span class="line">        square_of_sum = torch.sum(tmp, dim=1) ** 2</span><br><span class="line">        # bs,1,embedding_dim -&gt; bs,embedding_dim;; [bs,1,8]-&gt;bs,8</span><br><span class="line">        sum_of_square = torch.sum(tmp ** 2, dim=1)</span><br><span class="line">        # 加权线性层与FM层之和</span><br><span class="line">        x = linear_part + 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)</span><br><span class="line">        # sigmoid</span><br><span class="line">        x = torch.sigmoid(x.squeeze(1))</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure>
<h1 id="4-FFM"><a href="#4-FFM" class="headerlink" title="4.FFM"></a>4.FFM</h1><p>FFM在FM的基础上进行改进，提出了特征域的概念，特征域里是同一个特征的不同取值。FM做法对于不同特征交叉认为是同等重要的，然而FFM的理论是不同特征的交叉影响不同，举个简单例子。比如有性别、年龄、职业三种特征，那么在与“职业”中的“清洁工”特征交叉时“男性”的隐向量是<code>$v_{男性,职业}$</code>，在与“年龄”中的“中年”特征交叉时，“男性”的隐向量是<code>$v_{男性,年龄}$</code>。这种思维更符合实际场景，不同的特征交叉权重确实应该不同。</p>
<p>FFM使得本来仅取决于特征xi的向量vi还取决于与他交叉的特征xj 所属的特征域 fj，即变成了vifj 。 fj 是第 j 个特征所属的特征域，它有多个特征。</p>
<p>缺点:</p>
<ul>
<li>FFM公式无法化简，计算复杂度较高，FFM需要学习n个特征在f个域上的k维隐向量，参数量nfk个，复杂度<code>$O(kn^2)$</code></li>
</ul>
<p>核心代码：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class FieldAwareFactorizationMachine(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">        FFM </span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, field_dims, embed_dim):</span><br><span class="line">        super(FieldAwareFactorizationMachine, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)</span><br><span class="line"></span><br><span class="line">        # 输入的是label coder 用输出为1的embedding来形成linear part</span><br><span class="line">        # linear part</span><br><span class="line">        self.linear = torch.nn.Embedding(sum(field_dims) + 1, 1)</span><br><span class="line">        self.bias = torch.nn.Parameter(torch.zeros((1,)))</span><br><span class="line"></span><br><span class="line">        # ffm part</span><br><span class="line">        print(&quot;field_dims&quot;, field_dims)</span><br><span class="line">        self.num_fields = len(field_dims)  # 特征域的数目</span><br><span class="line">        self.embeddings = torch.nn.ModuleList([</span><br><span class="line">            torch.nn.Embedding(sum(field_dims), embed_dim) for _ in range(self.num_fields)</span><br><span class="line">        ])</span><br><span class="line">        for embedding in self.embeddings:</span><br><span class="line">            torch.nn.init.xavier_uniform_(embedding.weight.data)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # bs,fields_num [bs,22]</span><br><span class="line">        tmp = x + x.new_tensor(self.offsets).unsqueeze(0)</span><br><span class="line">        # linear part forward</span><br><span class="line">        ## bs,fields_num,1 -&gt; bs,1 [bs,22,1]-&gt;[bs,1]</span><br><span class="line">        linear_part = torch.sum(self.linear(tmp), dim=1) + self.bias</span><br><span class="line">        # ffm part forward</span><br><span class="line">        # 为每一个field都使用embedding进行映射编码</span><br><span class="line">        # 每个embedding中的shape应该为:bs,filed_num,embedding_num -&gt; bs,22,8</span><br><span class="line">        xs = [self.embeddings[i](x) for i in range(self.num_fields)]</span><br><span class="line">        ix = []</span><br><span class="line">        for i in range(self.num_fields - 1):</span><br><span class="line">            for j in range(i + 1, self.num_fields):</span><br><span class="line">                # xs[j].shape: torch.Size([2, 22, 8]) bs,field_nums,embedding_num</span><br><span class="line">                # xs[j].shape: torch.Size([2, 22, 8])</span><br><span class="line">                # xs[j][:, i] shape: torch.Size([2, 8]) bs,embedding_num</span><br><span class="line">                ix.append(xs[j][:, i] * xs[i][:, j])</span><br><span class="line">        # print(&quot;ix len:&quot;,len(ix)) 231</span><br><span class="line">        # print(&quot;ix [0]:&quot;,ix[0].shape) #bs,embdding_num -&gt; bs,8</span><br><span class="line">        ix = torch.stack(ix, dim=1)  # ix: -&gt; bs,231,embedding_num</span><br><span class="line">        ffm_part = torch.sum(torch.sum(ix, dim=1), dim=1, keepdim=True)  # bs,231,embedding_num -&gt; bs,embedding -&gt; bs,1</span><br><span class="line"></span><br><span class="line">        x = linear_part + ffm_part</span><br><span class="line">        x = torch.sigmoid(x.squeeze(1))</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure></p>
<h1 id="5-DeepFM"><a href="#5-DeepFM" class="headerlink" title="5.DeepFM"></a>5.DeepFM</h1><p>顾名思义，DeepFM是Deep与FM结合的产物，</p>
<p><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220713221459.png" alt></p>
<h3 id="5-1-Sparse-Feature"><a href="#5-1-Sparse-Feature" class="headerlink" title="5.1 Sparse Feature"></a>5.1 Sparse Feature</h3><p>Sparse Feature是指离散型变量。比如现在我有数据：xx公司每个员工的姓名、年龄、岗位、收入的表格，那么年龄和岗位就属于离散型变量，而收入则称为连续型变量。这从字面意思也能够理解。</p>
<p>Sparse Feature框里表示的是将每个特征经过one-hot编码后拼接在一起的稀疏长向量，黄色的点表示某对象在该特征的取值中属于该位置的值。</p>
<h3 id="5-2-Dense-Embeddings"><a href="#5-2-Dense-Embeddings" class="headerlink" title="5.2 Dense Embeddings"></a>5.2 Dense Embeddings</h3><p>该层为嵌入层，用于对高维稀疏的 01 向量做嵌入，得到低维稠密的向量 e (每个01向量对应自己的嵌入层，不同向量的嵌入过程相互独立，如上图所示）。然后将每个稠密向量横向拼接，在拼接上原始的数值特征，然后作为 Deep 与 FM 的输入。</p>
<p>最终输入模型的值如下图，Sparse Feature经过embedding之后，与归一化后的连续特征拼接，一起输入模型<br><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220713222246.png" alt></p>
<h3 id="5-3-FM-Layer"><a href="#5-3-FM-Layer" class="headerlink" title="5.3 FM Layer"></a>5.3 FM Layer</h3><p>线性部分 (黑色线段) 是给与每个特征一个权重，然后进行加权和；交叉部分 (红色线段) 是对特征进行两两相乘，然后赋予权重加权求和。然后将两部分结果累加在一起即为 FM Layer 的输出。</p>
<h3 id="5-4-Hidden-Layer"><a href="#5-4-Hidden-Layer" class="headerlink" title="5.4 Hidden Layer"></a>5.4 Hidden Layer</h3><p>Deep 部分的输入 为所有稠密向量的横向拼接，然后经过多层线性映射+非线性转换得到 Hidden Layer 的输出，一般会映射到1维，因为需要与 FM 的结果进行累加。</p>
<h3 id="5-5-Output-Units"><a href="#5-5-Output-Units" class="headerlink" title="5.5 Output Units"></a>5.5 Output Units</h3><p><code>$ DeepFM=sigmoid(y_{FM}+y_{DNN})$</code></p>
<p>输出层为 FM Layer 的结果与 Hidden Layer 结果的累加，低阶与高阶特征交互的融合，然后经过 sigmoid 非线性转换，得到预测的概率输出。</p>
<p>优点：</p>
<ul>
<li>两部分联合训练，无需加入人工特征，更易部署；</li>
<li>结构简单，复杂度低，两部分共享输入，共享信息，可更精确的训练学习。</li>
</ul>
<p>缺点：</p>
<ul>
<li>将类别特征对应的稠密向量拼接作为输入，然后对元素进行两两交叉。这样导致模型无法意识到域的概念，FM 与 Deep 两部分都不会考虑到域，属于同一个域的元素应该对应同样的计算。</li>
</ul>
<p>最后上核心代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DeepFM(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, feature_fields, embed_dim, mlp_dims, dropout):</span><br><span class="line">        super(DeepFM, self).__init__()</span><br><span class="line">        self.offsets = np.array((0, *np.cumsum(feature_fields)[:-1]), dtype=np.long)</span><br><span class="line"></span><br><span class="line">        # FM中的线性部分</span><br><span class="line">        self.linear = torch.nn.Embedding(sum(feature_fields) + 1, 1)</span><br><span class="line">        self.bias = torch.nn.Parameter(torch.zeros((1,)))</span><br><span class="line"></span><br><span class="line">        # Embedding层</span><br><span class="line">        self.embedding = torch.nn.Embedding(sum(feature_fields) + 1, embed_dim)</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.embedding.weight.data)</span><br><span class="line"></span><br><span class="line">        # DNN部分</span><br><span class="line">        self.embedding_out_dim = len(feature_fields) * embed_dim #22*8=176</span><br><span class="line">        layers = []</span><br><span class="line">        input_dim = self.embedding_out_dim</span><br><span class="line">        for mlp_dim in mlp_dims:</span><br><span class="line">            # 全连接层</span><br><span class="line">            layers.append(nn.Linear(input_dim, mlp_dim))</span><br><span class="line">            layers.append(nn.BatchNorm1d(mlp_dim))</span><br><span class="line">            layers.append(nn.ReLU())</span><br><span class="line">            layers.append(nn.Dropout(p=dropout))</span><br><span class="line">            input_dim = mlp_dim</span><br><span class="line">        layers.append(nn.Linear(input_dim, 1))</span><br><span class="line">        self.mlp = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        tmp = x + x.new_tensor(self.offsets).unsqueeze(0)</span><br><span class="line"></span><br><span class="line">        # embedding</span><br><span class="line">        embeddings = self.embedding(tmp)  # bs,fields_num,embedding_num-&gt;bs,22,8</span><br><span class="line"></span><br><span class="line">        # FM</span><br><span class="line">        ## linear part</span><br><span class="line">        linear_part = torch.sum(self.linear(tmp), dim=1) + self.bias</span><br><span class="line">        ## inner part</span><br><span class="line">        square_of_sum = torch.sum(embeddings, dim=1) ** 2</span><br><span class="line">        sum_of_square = torch.sum(embeddings ** 2, dim=1)</span><br><span class="line">        inner_part = 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)</span><br><span class="line"></span><br><span class="line">        fm_part = linear_part + inner_part#bs,1</span><br><span class="line"></span><br><span class="line">        # DNN part</span><br><span class="line">        mlp_part = self.mlp(embeddings.view(-1, self.embedding_out_dim))#bs,1</span><br><span class="line"></span><br><span class="line">        # 输出part</span><br><span class="line">        x = fm_part + mlp_part</span><br><span class="line">        x = torch.sigmoid(x.squeeze(1))</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure>
<h1 id="6-DCN"><a href="#6-DCN" class="headerlink" title="6.DCN"></a>6.DCN</h1><p>DCN是一个可以同时高效学习低维特征交叉和高维非线性特征的深度模型，不需要人工特征工程的同时需要的计算资源非常低。</p>
<p>DCN的模型结构图如下，其实模型结构已经较为详细说明了特征的交叉、运行过程。<br><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/v2-20d54f892a938ec967063de4d134bd19_1440w.jpg" alt></p>
<h3 id="6-1-Embedding-Layer"><a href="#6-1-Embedding-Layer" class="headerlink" title="6.1 Embedding Layer"></a>6.1 Embedding Layer</h3><p>输入的特征分为dense特征和sparse特征。对于sparse特征，通常使用one-hot等编码方式编码，之后通过embedding层进行映射降维，转为dense特征。最后将dense特征与转换过的sparse特征拼接，即图中的x0.</p>
<h3 id="6-2-Cross-Network"><a href="#6-2-Cross-Network" class="headerlink" title="6.2 Cross Network"></a>6.2 Cross Network</h3><p>在交叉层中，使用图中的公式进行特征交叉，并且叠加L层</p>
<p><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220727234244.png" alt></p>
<p>w和b是需要学习的参数，cross network为1层的时候，我们可以得到的最高是2维的特征交叉；cross network为2层的时候，我们得到的是最高3维的特征交叉；cross network为3层的时候，我们得到的是最高4维的特征交叉；以此类推。。。</p>
<p>因此cross network以一种参数共享的方式，通过对叠加层数的控制，可以高效地学习出低维的特征交叉组合，避免了人工特征工程。</p>
<h3 id="6-3-Deep-Network"><a href="#6-3-Deep-Network" class="headerlink" title="6.3 Deep Network"></a>6.3 Deep Network</h3><p>为全连接网络，用来学习高维非线性特征交叉组合。</p>
<h3 id="6-4-Combination-Output-Layer"><a href="#6-4-Combination-Output-Layer" class="headerlink" title="6.4 Combination Output Layer"></a>6.4 Combination Output Layer</h3><p>将cross与deep层输出拼接，然后过一个sigmoid进行CTR预估。</p>
<p>最后上核心代码：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line">class DeepCrossNet(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">        Deep Cross Network</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def __init__(self, feature_fields, embed_dim, num_layers, mlp_dims, dropout):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        super(DeepCrossNet, self).__init__()</span><br><span class="line">        self.feature_fields = feature_fields</span><br><span class="line">        self.offsets = np.array((0, *np.cumsum(feature_fields)[:-1]), dtype = np.long)</span><br><span class="line">        </span><br><span class="line">        # Embedding layer</span><br><span class="line">        self.embedding = nn.Embedding(sum(feature_fields)+1, embed_dim)</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.embedding.weight.data)</span><br><span class="line">        self.embedding_out_dim = len(feature_fields) * embed_dim</span><br><span class="line">        </span><br><span class="line">        #DNN layer</span><br><span class="line">        dnn_layers = []</span><br><span class="line">        input_dim = self.embedding_out_dim</span><br><span class="line">        self.mlp_dims = mlp_dims</span><br><span class="line">        for mlp_dim in mlp_dims:</span><br><span class="line">            # 全连接层</span><br><span class="line">            dnn_layers.append(nn.Linear(input_dim, mlp_dim))</span><br><span class="line">            dnn_layers.append(nn.BatchNorm1d(mlp_dim))</span><br><span class="line">            dnn_layers.append(nn.ReLU())</span><br><span class="line">            dnn_layers.append(nn.Dropout(p = dropout))</span><br><span class="line">            input_dim = mlp_dim</span><br><span class="line">        self.mlp = nn.Sequential(*dnn_layers)      </span><br><span class="line">    </span><br><span class="line">        # Corss Net layer</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.cross_w = nn.ModuleList([</span><br><span class="line">                nn.Linear(self.embedding_out_dim, 1, bias=False) for _ in range(num_layers)</span><br><span class="line">        ])</span><br><span class="line">        self.cross_b = nn.ParameterList([</span><br><span class="line">                nn.Parameter(torch.zeros((self.embedding_out_dim,))) for _ in range(num_layers)</span><br><span class="line">        ])</span><br><span class="line">        </span><br><span class="line">        # LR layer</span><br><span class="line">        self.lr = nn.Linear(self.mlp_dims[-1]+self.embedding_out_dim, 1)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    def forward(self, x):</span><br><span class="line">        tmp = x + x.new_tensor(self.offsets).unsqueeze(0)</span><br><span class="line">        </span><br><span class="line">        # embeded dense vector</span><br><span class="line">        embeded_x = self.embedding(tmp).view(-1, self.embedding_out_dim)</span><br><span class="line">        # DNN out</span><br><span class="line">        mlp_part = self.mlp(embeded_x)</span><br><span class="line">        # Cross Net out</span><br><span class="line">        x0 = embeded_x</span><br><span class="line">        cross = embeded_x</span><br><span class="line">        for i in range(self.num_layers):</span><br><span class="line">            xw = self.cross_w[i](cross)</span><br><span class="line">            cross = x0 * xw + self.cross_b[i] + cross</span><br><span class="line">        </span><br><span class="line">        # stack output</span><br><span class="line">        out = torch.cat([cross, mlp_part], dim = 1)</span><br><span class="line">        </span><br><span class="line">        # LR out</span><br><span class="line">        out = self.lr(out)</span><br><span class="line">        out = torch.sigmoid(out.squeeze(1))</span><br><span class="line">        </span><br><span class="line">        return out</span><br></pre></td></tr></table></figure></p>
<h1 id="7-DCN-v2"><a href="#7-DCN-v2" class="headerlink" title="7.DCN_v2"></a>7.DCN_v2</h1><p>DCN-v2优化了DCN的cross layer，权重参数w由原来的vector变为方阵matrix，增加了网络层的表达能力；同时，为了保证线上应用的耗时不会因为cross layer参数量的增加而增加。观察到cross layer的matrix具有低秩性，使用矩阵分解，将方阵matrix转换为两个低维的矩阵、最后在低秩空间内，利用MoE多专家系统，对特征交叉做非线性变化，进一步增加对交叉特征的建模。直接上图，一目了然：</p>
<p><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220728000821.png" alt></p>
<p>网络层权重参数由原来的vector w变为matrix W。DCN网络的cross layer的建模是element-wise；DCNv2 cross layer可以实现element-wise和feature-wise的特征交叉。但是这样直接转为矩阵，会极大增加计算量，且可能创新点太少？因此作者进行了相应的改进。</p>
<p><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220728000738.png" alt></p>
<p><strong>创新点一:</strong> 由于将特征embedding之后再拼接起来成了一个d维的向量，这个d太大了，而矩阵W维度是<code>$d * d$</code> 。所有导致这个计算的复杂度就很高了，于是我们可以<code>$W=UV^T$</code><br> ，类似于矩阵分解的方法，将维度比较大的<code>$d * d$</code> 矩阵分解成两个维度小一些的<code>$d * r$</code>矩阵。其中r r远小于d。这种方法叫做矩阵的低阶分解，和SVD有点类似。这也我们的交叉公式就发生了变化:<br><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220728001856.png" alt></p>
<p>参数的数量和运算的复杂度都有效的变低了。</p>
<p><strong>创新点二:</strong> 低维空间的交叉特征建模使得我们可以利用MoE。MoE由两部分组成：experts专家和gating门（一个关于输入x的函数）。我们可以使用多个专家，每个专家学习不同的交叉特征，最后通过gating将各个专家的学习结果整合起来，作为输出。这样就又能进一步增加对交叉特征的建模能力。<br><img src="https://rxk-1300064984.cos.ap-nanjing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220728002152.png" alt></p>
<p>G是一个门函数，通常为sigmoid或者softmax。</p>
<p>改进的后模型据作者所说在降低了30%的复杂度的情况下，保留了模型的精度。附上核心代码：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line">class CrossNetMatrix(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">        CrossNet of DCN-v2</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, in_features, layer_num=2):</span><br><span class="line">        super(CrossNetMatrix, self).__init__()</span><br><span class="line">        self.layer_num = layer_num</span><br><span class="line">        # Cross中的W参数 (layer_num,  [W])</span><br><span class="line">        self.weights = nn.Parameter(torch.Tensor(self.layer_num, in_features, in_features))</span><br><span class="line">        # Cross中的b参数 (layer_num, [B])</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(self.layer_num, in_features, 1))</span><br><span class="line"></span><br><span class="line">        # Init</span><br><span class="line">        for i in range(self.layer_num):</span><br><span class="line">            nn.init.xavier_normal_(self.weights[i])</span><br><span class="line">        for i in range(self.layer_num):</span><br><span class="line">            nn.init.zeros_(self.bias[i])</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">            x : batch_size  *  in_features</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        x0 = x.unsqueeze(2)</span><br><span class="line">        xl = x.unsqueeze(2)</span><br><span class="line">        for i in range(self.layer_num):</span><br><span class="line">            tmp = torch.matmul(self.weights[i], xl) + self.bias[i]</span><br><span class="line">            xl = x0 * tmp + xl</span><br><span class="line">        xl = xl.squeeze(2)</span><br><span class="line">        </span><br><span class="line">        return xl</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">class CrossNetMix(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">        CrossNet of DCN-V2 with Mixture of Low-rank Experts</span><br><span class="line">        公式如下：</span><br><span class="line">            G_i(xl) = Linear(xl)</span><br><span class="line">            E_i(xl) = x0·(Ul*g(Cl*g(Vl*xl)) + bl)</span><br><span class="line">            g() = tanh activate func</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, in_features, low_rank = 16, expert_num = 4, layer_num=2):</span><br><span class="line">        super(CrossNetMix, self).__init__()</span><br><span class="line">        self.layer_num = layer_num</span><br><span class="line">        self.expert_num = expert_num</span><br><span class="line">        </span><br><span class="line">        # Cross中的U参数(layer_num, expert_num, in_features, low_rank)</span><br><span class="line">        self.U_params = nn.Parameter(torch.Tensor(layer_num, expert_num, in_features, low_rank))</span><br><span class="line">        # Cross中的V^T参数(layer_num, expert_num, low_rank, in_features)</span><br><span class="line">        self.V_params = nn.Parameter(torch.Tensor(layer_num, expert_num, low_rank, in_features))</span><br><span class="line">        # Cross中的C参数(layer_num, expert_num, low_rank, low_rank)</span><br><span class="line">        self.C_params = nn.Parameter(torch.Tensor(layer_num, expert_num, low_rank, low_rank))</span><br><span class="line">        # Cross中的bias(layer_num, in_features, 1)</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(layer_num, in_features, 1))</span><br><span class="line">        </span><br><span class="line">        # MOE 中的门控gate</span><br><span class="line">        self.gates = nn.ModuleList([nn.Linear(in_features, 1, bias=False) for i in range(expert_num)])</span><br><span class="line">        </span><br><span class="line">        # Init</span><br><span class="line">        for i in range(self.layer_num):</span><br><span class="line">            nn.init.xavier_normal_(self.U_params[i])</span><br><span class="line">            nn.init.xavier_normal_(self.V_params[i])</span><br><span class="line">            nn.init.xavier_normal_(self.C_params[i])</span><br><span class="line">        for i in range(self.layer_num):</span><br><span class="line">            nn.init.zeros_(self.bias[i])</span><br><span class="line">            </span><br><span class="line">    def forward(self, x):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">            x : batch_size  *  in_features</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        x0 = x.unsqueeze(2)</span><br><span class="line">        xl = x.unsqueeze(2)</span><br><span class="line">        for i in range(self.layer_num):</span><br><span class="line">            expert_outputs = []</span><br><span class="line">            gate_scores = []</span><br><span class="line">            for expert in range(self.expert_num):</span><br><span class="line">                # gate score : G(xl)</span><br><span class="line">                gate_scores.append(self.gates[expert](xl.squeeze(2)))</span><br><span class="line">        </span><br><span class="line">                # cross part</span><br><span class="line">                # g(Vl·xl))</span><br><span class="line">                tmp = torch.tanh(torch.matmul(self.V_params[i][expert], xl))</span><br><span class="line">                # g(Cl·g(Vl·xl))</span><br><span class="line">                tmp = torch.tanh(torch.matmul(self.C_params[i][expert], tmp))</span><br><span class="line">                # Ul·g(Cl·g(Vl·xl)) + bl</span><br><span class="line">                tmp =  torch.matmul(self.U_params[i][expert], tmp) + self.bias[i]</span><br><span class="line">                # E_i(xl) = x0·(Ul·g(Cl·g(Vl·xl)) + bl)</span><br><span class="line">                tmp = x0 * tmp                </span><br><span class="line">                expert_outputs.append(tmp.squeeze(2))</span><br><span class="line">            </span><br><span class="line">            expert_outputs = torch.stack(expert_outputs, 2) # batch * in_features * expert_num</span><br><span class="line">            gate_scores = torch.stack(gate_scores, 1) # batch * expert_num * 1</span><br><span class="line">            MOE_out = torch.matmul(expert_outputs, gate_scores.softmax(1))</span><br><span class="line">            xl = MOE_out + xl  # batch * in_features * 1</span><br><span class="line">        </span><br><span class="line">        xl = xl.squeeze(2)</span><br><span class="line">        </span><br><span class="line">        return xl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DeepCrossNetv2(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">        Deep Cross Network V2</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def __init__(self, feature_fields, embed_dim, layer_num, mlp_dims, dropout = 0.1,</span><br><span class="line">                 cross_method = &apos;Mix&apos;, model_method = &apos;parallel&apos;):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        super(DeepCrossNetv2, self).__init__()</span><br><span class="line">        self.feature_fields = feature_fields</span><br><span class="line">        self.offsets = np.array((0, *np.cumsum(feature_fields)[:-1]), dtype = np.long)</span><br><span class="line">        self.model_method = model_method</span><br><span class="line">        </span><br><span class="line">        # Embedding layer</span><br><span class="line">        self.embedding = nn.Embedding(sum(feature_fields)+1, embed_dim)</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.embedding.weight.data)</span><br><span class="line">        self.embedding_out_dim = len(feature_fields) * embed_dim</span><br><span class="line">        </span><br><span class="line">        #DNN layer</span><br><span class="line">        dnn_layers = []</span><br><span class="line">        input_dim = self.embedding_out_dim</span><br><span class="line">        self.mlp_dims = mlp_dims</span><br><span class="line">        for mlp_dim in mlp_dims:</span><br><span class="line">            # 全连接层</span><br><span class="line">            dnn_layers.append(nn.Linear(input_dim, mlp_dim))</span><br><span class="line">            dnn_layers.append(nn.BatchNorm1d(mlp_dim))</span><br><span class="line">            dnn_layers.append(nn.ReLU())</span><br><span class="line">            dnn_layers.append(nn.Dropout(p = dropout))</span><br><span class="line">            input_dim = mlp_dim</span><br><span class="line">        self.mlp = nn.Sequential(*dnn_layers)      </span><br><span class="line">        </span><br><span class="line">        if cross_method == &apos;Mix&apos;:</span><br><span class="line">            self.CrossNet = CrossNetMix(in_features=self.embedding_out_dim)</span><br><span class="line">        elif cross_method == &apos;Matrix&apos;:</span><br><span class="line">            self.CrossNet = CrossNetMatrix(in_features=self.embedding_out_dim)</span><br><span class="line">        else:</span><br><span class="line">            raise NotImplementedError</span><br><span class="line">    </span><br><span class="line">        # predict layer</span><br><span class="line">        if self.model_method == &apos;parallel&apos;:</span><br><span class="line">            self.fc = nn.Linear(self.mlp_dims[-1]+self.embedding_out_dim, 1)</span><br><span class="line">        elif self.model_method == &apos;stack&apos;:</span><br><span class="line">            self.fc = nn.Linear(self.mlp_dims[-1], 1)</span><br><span class="line">        else:</span><br><span class="line">            raise NotImplementedError</span><br><span class="line">        </span><br><span class="line">    def forward(self, x):</span><br><span class="line">        tmp = x + x.new_tensor(self.offsets).unsqueeze(0)</span><br><span class="line">        </span><br><span class="line">        # embeded dense vector</span><br><span class="line">        embeded_x = self.embedding(tmp).view(-1, self.embedding_out_dim)</span><br><span class="line">        if self.model_method == &apos;parallel&apos;:</span><br><span class="line">            # DNN out</span><br><span class="line">            mlp_part = self.mlp(embeded_x)</span><br><span class="line">            # Cross part</span><br><span class="line">            cross = self.CrossNet(embeded_x)</span><br><span class="line">            # stack output</span><br><span class="line">            out = torch.cat([cross, mlp_part], dim = 1)</span><br><span class="line">        elif self.model_method == &apos;stack&apos;:</span><br><span class="line">            # Cross part</span><br><span class="line">            cross = self.CrossNet(embeded_x)</span><br><span class="line">            # DNN out</span><br><span class="line">            out = self.mlp(cross)</span><br><span class="line">        # predict out</span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        out = torch.sigmoid(out.squeeze(1))</span><br><span class="line">        </span><br><span class="line">        return out</span><br></pre></td></tr></table></figure></p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>[1] <a href="https://blog.csdn.net/weixin_44556141/article/details/120790057" target="_blank" rel="noopener">https://blog.csdn.net/weixin_44556141/article/details/120790057</a></p>
<p>[2] <a href="https://zhuanlan.zhihu.com/p/354994307" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/354994307</a></p>
<p>[3] <a href="https://blog.csdn.net/Jeremiah_/article/details/120740877" target="_blank" rel="noopener">https://blog.csdn.net/Jeremiah_/article/details/120740877</a></p>
<p>[4] <a href="https://zhuanlan.zhihu.com/p/361451464" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/361451464</a></p>
<p>[5] <a href="https://zhuanlan.zhihu.com/p/422141936" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/422141936</a></p>
<p>[6] <a href="https://zhuanlan.zhihu.com/p/138358291" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/138358291</a></p>
<p>[7] <a href="https://zhuanlan.zhihu.com/p/344634505" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/344634505</a></p>
<p>[8] <a href="https://github.com/Prayforhanluo/CTR_Algorithm" target="_blank" rel="noopener">https://github.com/Prayforhanluo/CTR_Algorithm</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">CinKate</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://renxingkai.github.io/2022/07/14/deeprec/">http://renxingkai.github.io/2022/07/14/deeprec/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/排序-推荐系统/">排序 - 推荐系统</a></div><div class="social-share pull-right" data-disabled="google,facebook"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2022/08/17/cpp-base/"><i class="fa fa-chevron-left">  </i><span>C++新特性系列一：基础知识</span></a></div><div class="next-post pull-right"><a href="/2022/03/26/paper-lstm-ved/"><span>Learning Robust Models for e-Commerce Product Search阅读笔记</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(http://p17.qhimg.com/d/_open360/fengjing0403/21.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2019 - 2022 By CinKate</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://renxingkai.github.io">blog</a>!</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>